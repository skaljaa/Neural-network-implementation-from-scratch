{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow/Keras Neural Network - MNIST Classification\n",
    "\n",
    "This notebook demonstrates building a neural network with TensorFlow/Keras in just a few lines of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_mnist():\n",
    "    \"\"\"Load and preprocess MNIST dataset with error handling.\"\"\"\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # Try to load MNIST from OpenML\n",
    "        mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "        X, y = mnist.data.to_numpy(), mnist.target.to_numpy().astype(int)\n",
    "        \n",
    "        # Use subset for faster training\n",
    "        X, _, y, _ = train_test_split(X, y, train_size=10000, random_state=42, stratify=y)\n",
    "        \n",
    "        # Split into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading from OpenML: {e}\")\n",
    "        print(\"Loading from Keras instead...\")\n",
    "        \n",
    "        # Alternative: Load from Keras\n",
    "        (X_train_full, y_train_full), (X_test_full, y_test_full) = keras.datasets.mnist.load_data()\n",
    "        \n",
    "        # Flatten and use subset\n",
    "        X_train = X_train_full[:8000].reshape(8000, -1)\n",
    "        X_test = X_test_full[:2000].reshape(2000, -1)\n",
    "        y_train = y_train_full[:8000]\n",
    "        y_test = y_test_full[:2000]\n",
    "    \n",
    "    print(f\"Train samples: {X_train.shape[0]}\")\n",
    "    print(f\"Test samples: {X_test.shape[0]}\")\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    y_train = y_train.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    \n",
    "    print(f\"âœ“ Data loaded and preprocessed successfully!\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Neural Network Model\n",
    "\n",
    "Architecture: 784 â†’ 128 â†’ 64 â†’ 10\n",
    "\n",
    "**Look how simple this is compared to NumPy implementation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensorflow_model():\n",
    "    \"\"\"\n",
    "    Create a neural network using TensorFlow/Keras.\n",
    "    Same architecture as NumPy version: 784 -> 128 -> 64 -> 10\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(784,)),  # Input layer\n",
    "        keras.layers.Dense(128, activation='relu'),  # Hidden layer 1\n",
    "        keras.layers.Dense(64, activation='relu'),   # Hidden layer 2\n",
    "        keras.layers.Dense(10, activation='softmax') # Output layer\n",
    "    ])\n",
    "    \n",
    "    # Compile model with same settings as NumPy version\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=0.1),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_and_preprocess_mnist()\n",
    "\n",
    "# Create model\n",
    "print(\"\\nCreating TensorFlow model...\")\n",
    "model = create_tensorflow_model()\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training TensorFlow model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Simple training with progress bar\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,  # Reduced for faster notebook execution\n",
    "    batch_size=32,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "tf_training_time = time.time() - start_time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Training completed in {tf_training_time:.2f} seconds!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating TensorFlow model...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Training Time: {tf_training_time:.2f} seconds\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2, color='#667eea')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2, color='#f5576c')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Loss vs Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, color='#43e97b')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='#667eea')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Accuracy vs Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions on Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test[:10], verbose=0)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = y_test[:10]\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle('Sample Predictions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Reshape to 28x28 image\n",
    "    image = X_test[i].reshape(28, 28)\n",
    "    pred = predicted_classes[i]\n",
    "    true = true_classes[i]\n",
    "    \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    color = 'green' if pred == true else 'red'\n",
    "    ax.set_title(f'Pred: {pred} | True: {true}', \n",
    "                fontsize=11, color=color, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy on these 10 samples: {np.mean(predicted_classes == true_classes)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary: TensorFlow vs NumPy\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "| Aspect | NumPy (From Scratch) | TensorFlow/Keras |\n",
    "|--------|---------------------|------------------|\n",
    "| **Lines of Code** | ~300 lines | ~15 lines |\n",
    "| **Forward Pass** | Manual implementation | Automatic |\n",
    "| **Backpropagation** | Manual gradients | Automatic |\n",
    "| **Optimization** | Manual updates | Built-in |\n",
    "| **GPU Support** | No | Yes |\n",
    "| **Complexity** | High | Low |\n",
    "| **Learning Value** | Understand internals | Build quickly |\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "âœ… **NumPy**: Great for learning how neural networks work internally  \n",
    "âœ… **TensorFlow**: Great for building real-world applications  \n",
    "\n",
    "**Both are valuable!** ðŸŽ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Optional) Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('mnist_model.keras')\n",
    "print(\"âœ“ Model saved as 'mnist_model.keras'\")\n",
    "\n",
    "# You can load it later with:\n",
    "# loaded_model = keras.models.load_model('mnist_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
